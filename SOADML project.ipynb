{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider:\n",
    "- $x_1,..., x_n$ $\\in$ $\\mathbb{R}^d$\n",
    "- $y_1,...,y_n$ $\\in$ $(-1, 1)$\n",
    "- $\\lambda > 0$ a regularization parameter\n",
    "- $\\phi_1,...,\\phi_n$ a sequence of scalars convex functions\n",
    "- Since we are working on the SVM problem (with linear kernels and no bias term), we set $\\phi_i(a) = max(0,1-y_ia)$\n",
    "\n",
    "For solving SVM, there are 2 approaches:\n",
    "- stochastic gradient descent (SGD), which aims to minimize the following primal problem:\n",
    "\\begin{equation}\n",
    "min_{w \\text{ } \\in \\text{ } R^d} \\big[ \\frac{1}{n} \\sum\\limits_{i=1}^n \\phi_i(w^Tx_i) + \\frac{\\lambda}{2}||w||^2\\big]\n",
    "\\end{equation}\n",
    "- dual coordinate ascent (DCA), which aims to maximize the following dual problem:\n",
    "\\begin{equation}\n",
    "max_{\\alpha \\text{ } \\in \\text{ } R^n} \\big[ \\frac{1}{n} \\sum\\limits_{i=1}^n -\\phi_i^*(-\\alpha_i) - \\frac{\\lambda}{2} \\big|\\big|\\frac{1}{\\lambda n}\\sum\\limits_{i=1}^n \\alpha_i x_i \\big|\\big|^2\\big]\n",
    "\\end{equation}\n",
    "here, for each $i$, $\\phi_i^*: \\mathbb{R} \\rightarrow \\mathbb{R}$ is the convex conjugate of $\\phi_i$, namely $\\phi_i^*(u) = max_z(zu - \\phi_i(z))$\n",
    "\n",
    "If we define, $w(\\alpha) = \\frac{1}{\\lambda n}\\sum\\limits_{i=1}^n \\alpha_i x_i$, then we have that $w(\\alpha^*) = w^*$ where $\\alpha^*$ is an optimal solution of the dual problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___Procedure SDCA($\\alpha^{(0)}$)___</center>\n",
    "***\n",
    "___Let___ $w^{(0)} = w(\\alpha^{(0)})$<br>\n",
    "___Iterate:___ for $t=1,2,...,T:$\n",
    "> Randomly pick $i$<br>\n",
    "Find $\\Delta\\alpha_i$ to maximize $-\\phi_i^*(-(\\alpha_i^{(t-1)}+\\Delta\\alpha_i)) - \\frac{\\lambda n}{2} ||w^{(t-1)}+(\\lambda n)^{-1} \\Delta\\alpha_ix_i||^2$<br>\n",
    "$\\alpha^{(t)} \\leftarrow \\alpha^{(t-1)}+\\Delta\\alpha_ie_i$ WHAT IS THIS $e_i$<br>\n",
    "$w^{(t)} \\leftarrow w^{(t-1)}+(\\lambda n)^{-1}\\Delta\\alpha_ix_i$<br>\n",
    " \n",
    "___Output (Averaging option):___<br>\n",
    "> Let $\\bar{\\alpha} = \\frac{1}{T-T_0}\\sum\\limits_{i=T_0+1}^T \\alpha^{(t-1)}$<br>\n",
    "Let $\\bar{w} = w(\\bar{\\alpha}) = \\frac{1}{T-T_0}\\sum\\limits_{i=T_0+1}^T w^{(t-1)}$<br>\n",
    "return $\\bar{w}$<br>\n",
    "\n",
    "___Output (Random option):___<br>\n",
    "> Let $\\bar{\\alpha} = \\alpha^{(t)}$ and $\\bar{w} = w^{(t)}$ for some random $t \\in T_0+1,...T$<br>\n",
    "return $\\bar{w}$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___Procedure Modified-SGD___</center>\n",
    "***\n",
    "___Initialize:___ $w^{(0)} = 0$<br>\n",
    "___Iterate:___ for $t=1,2,...,n:$<br>\n",
    "> Find $\\alpha_t$ to maximize $-\\phi_t^*(-\\alpha_t^) - \\frac{\\lambda t}{2} ||w^{(t-1)}+(\\lambda t)^{-1} \\alpha_tx_t||^2$<br>\n",
    "Let $w^{(t)} = \\frac{1}{\\lambda t}\\sum\\limits_{i=1}^t \\alpha_ix_i$<br>\n",
    "return $\\alpha$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___Procedure SDCA with SGD Initialization___</center>\n",
    "***\n",
    "___Stage 1:___ call Procedure Modified-SGD and obtain $\\alpha$<br>\n",
    "___Stage 2:___ call Procedure SDCA with parameter $\\alpha^{(0)} = \\alpha$<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___Procedure SDCA-Perm($\\alpha^{(0)}$)___</center>\n",
    "***\n",
    "___Let___ $w^{(0)} = w(\\alpha^{(0)})$<br>\n",
    "___Let___ $t=0$<br>\n",
    "___Iterate:___ for epoch $k=1,2,...$<br>\n",
    "> ___Let___ ${i_1,...,i_n}$ be a random permutation of ${1,...,n}$<br>\n",
    "___Iterate:___ for $j=1,2,...,n:$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $t \\leftarrow t+1$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $i=i_j$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Find $\\Delta\\alpha_i$ to increase dual<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $\\alpha^{(t)} \\leftarrow \\alpha^{(t-1)}+\\Delta\\alpha_ie_i$ WHAT IS THIS $e_i$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $w^{(t)} \\leftarrow w^{(t-1)}+(\\lambda n)^{-1}\\Delta\\alpha_ix_i$<br>\n",
    " \n",
    "___Output (Averaging option):___<br>\n",
    "> Let $\\bar{\\alpha} = \\frac{1}{T-T_0}\\sum\\limits_{i=T_0+1}^T \\alpha^{(t-1)}$<br>\n",
    "Let $\\bar{w} = w(\\bar{\\alpha}) = \\frac{1}{T-T_0}\\sum\\limits_{i=T_0+1}^T w^{(t-1)}$<br>\n",
    "return $\\bar{w}$<br>\n",
    "\n",
    "___Output (Random option):___<br>\n",
    "> Let $\\bar{\\alpha} = \\alpha^{(t)}$ and $\\bar{w} = w^{(t)}$ for some random $t \\in T_0+1,...T$<br>\n",
    "return $\\bar{w}$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pegasos algorithm performs stochastic gradient descent on the primal objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___The basic Pegasos algorithm___</center>\n",
    "***\n",
    "___Let___ $w^{(0)} = (0,...,0)$<br>\n",
    "___Iterate:___ for $t=1,2,...,T:$\n",
    "> Randomly pick $i$<br>\n",
    "Set $\\eta_t = \\frac{1}{\\lambda t}$<br>\n",
    "If $y_i \\langle\\, w_{t-1},x_i\\rangle < 1$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $w_t \\leftarrow (1-\\eta_t \\lambda)w_{t-1} + \\eta_t y_i x_i$<br>\n",
    "Else:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $w_t \\leftarrow (1-\\eta_t \\lambda)w_{t-1}$<br>\n",
    "[Optional: $w_t \\leftarrow min\\big\\{1, \\frac{1/\\sqrt{\\lambda}}{||w_t||}\\big\\}w_t$]\n",
    "\n",
    " \n",
    "___Output:___<br>\n",
    "> return $w_T$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the optional projection step to the previous algorithm to limit the set of admissible solutions to the ball of radius $\\frac{1}{\\sqrt{\\lambda}}$. However, in the experiments, there is no major differences between the projected and unprojected variants of Pegasos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mini-batch setting of this algorithm can be used by using k examples at each iteration, where 1 ≤ k ≤ n is a parameter that needs to be provided to the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___The mini-batch Pegasos algorithm___</center>\n",
    "***\n",
    "___Let___ $w^{(0)} = (0,...,0)$<br>\n",
    "___Iterate:___ for $t=1,2,...,T:$\n",
    "> Randomly pick $A_t \\subseteq [n]$, where $|A_t|=k$<br>\n",
    "Set $A_t^+ = \\{i \\in A_t:y_i \\langle\\, w_{t-1},x_i\\rangle < 1 \\}$ <br>\n",
    "Set $\\eta_t = \\frac{1}{\\lambda t}$<br>\n",
    "Set $w_t \\leftarrow (1-\\eta_t \\lambda)w_{t-1} + \\frac{\\eta_t}{k}\\sum\\limits_{i \\in A_t^+} y_i x_i$<br>\n",
    "[Optional: $w_t \\leftarrow min\\big\\{1, \\frac{1/\\sqrt{\\lambda}}{||w_t||}\\big\\}w_t$]\n",
    "\n",
    " \n",
    "___Output:___<br>\n",
    "> return $w_T$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above description we refer to $A_t$ as chosen uniformly at random among the subsets of $[n]$ of size $k$, i.e. chosen without repetitions. Notice that the analysis still holds when $A_t$ is a multi-set chosen i.i.d. with repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>___The kernalized Pegasos algorithm___</center>\n",
    "***\n",
    "___Let___ $w^{(0)} = (0,...,0)$<br>\n",
    "___Iterate:___ for $t=1,2,...,T:$\n",
    "> Randomly pick $A_t \\subseteq [n]$, where $|A_t|=k$<br>\n",
    "Set $A_t^+ = \\{i \\in A_t:y_i \\langle\\, w_{t-1},x_i\\rangle < 1 \\}$ <br>\n",
    "Set $\\eta_t = \\frac{1}{\\lambda t}$<br>\n",
    "Set $w_t \\leftarrow (1-\\eta_t \\lambda)w_{t-1} + \\frac{\\eta_t}{k}\\sum\\limits_{i \\in A_t^+} y_i x_i$<br>\n",
    "[Optional: $w_t \\leftarrow min\\big\\{1, \\frac{1/\\sqrt{\\lambda}}{||w_t||}\\big\\}w_t$]\n",
    "\n",
    " \n",
    "___Output:___<br>\n",
    "> return $w_T$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
